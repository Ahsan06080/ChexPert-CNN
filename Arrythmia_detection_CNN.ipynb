{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arrythmia_detection_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ezekiel112/ChexPert-CNN/blob/main/Arrythmia_detection_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVVd0uIPYhto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c37659d-62bd-4c06-bbdb-f5d9d9c556c5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 12 17:06:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNnEf3oMnqT3",
        "outputId": "f82f9cb3-03c6-42dd-c484-c91be6e036df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFHccQWXnqMN"
      },
      "source": [
        "import shutil\n",
        "shutil.copyfile('/content/drive/MyDrive/Thesis.zip', './arrhythmia_detection_ECG.zip')\n",
        "!unzip arrhythmia_detection_ECG.zip\n",
        "#os.remove(\"arrhythmia_detection_ECG.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04zx6Dz4qyTk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e1fccbfb-ceb5-4a64-cc1e-de342c662393"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skabvCUMoOQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5084f8-18c7-4b39-96f5-e2d15d3a34e0"
      },
      "source": [
        "%cd Thesis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copyfile('/content/drive/MyDrive/training_data.zip', './training_data.zip')\n",
        "shutil.copyfile('/content/drive/MyDrive/test_data.zip', './test.zip')\n",
        "!unzip training_data\n",
        "!unzip test_data\n",
        "!unzip test.zip"
      ],
      "metadata": {
        "id": "e-40P4V85wJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-6a8tDeqUb5"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np, os, sys, joblib\n",
        "import matplotlib.pyplot as pl\n",
        "import pandas as pd\n",
        "import random, os\n",
        "import librosa\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        " #from torch.utils.data import random_split\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import tqdm\n",
        "from evaluate_model import *\n",
        "from my_helper_code import *\n",
        "from helper_code import *\n",
        "from model import *\n",
        "from torch.nn import  Conv1d,Conv2d\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7WIyCeqW0M"
      },
      "source": [
        "def seed_everything(seed: int):\n",
        "    \n",
        "    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVJNrHVnqZ-W",
        "outputId": "9a47f56a-99e5-4aa6-8b68-7f35308839fc"
      },
      "source": [
        "df = pd.read_csv('dx_mapping_scored.csv')\n",
        "labels = df['SNOMEDCTCode'].values\n",
        "labels = [str(i) for i in labels]\n",
        "classes = list(labels)\n",
        "train_data_directory = 'training_data'\n",
        "train_header_files, train_recording_files = find_challenge_files(train_data_directory)\n",
        "train_num_recordings = len(train_recording_files)\n",
        "twelve_leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6')\n",
        "six_leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF')\n",
        "four_leads = ('I', 'II', 'III', 'V2')\n",
        "three_leads = ('I', 'II', 'V2')\n",
        "two_leads = ('I', 'II')\n",
        "lead_sets = (twelve_leads, six_leads, four_leads, three_leads, two_leads)\n",
        "\n",
        "test_data_directory = 'test_data'\n",
        "test_header_files, test_recording_files = find_challenge_files(test_data_directory)\n",
        "test_num_recordings = len(test_recording_files)\n",
        "training_classes = list(labels)\n",
        "test_classes = list(labels)\n",
        "num_classes = len(classes)\n",
        "num_classes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk-9LVVJqiFt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN1A0Xhfqc6y"
      },
      "source": [
        "class My_Dataset_separate(Dataset) :\n",
        "    def __init__(self,header_files, recording_files, leads, sample_length, sample_rate = 500) :\n",
        "        super(Dataset,self).__init__()\n",
        "        self.header_files = header_files\n",
        "        self.recording_files = recording_files\n",
        "        self.leads = leads\n",
        "        self.sample_length = sample_length    \n",
        "        self.sample_rate = sample_rate\n",
        "    def __len__(self) :\n",
        "         \n",
        "        return len(self.recording_files)\n",
        "    \n",
        "    def __getitem__(self,index) :\n",
        "        header = load_header(self.header_files[index])\n",
        "        orig_sr = int(header.split(' ')[2])\n",
        "        #print(orig_sr)\n",
        "        recording = load_recording(self.recording_files[index])\n",
        "        recordings = choose_leads(recording, header, self.leads)\n",
        "        data = np.zeros((recordings.shape[0],self.sample_length))\n",
        "        for i in range(len(recordings)):\n",
        "            #print(type(data[i]))\n",
        "            y = librosa.resample(recordings[i].astype(np.float), orig_sr, self.sample_rate, res_type='kaiser_best') \n",
        "            #print(y.shape[0])\n",
        "            if y.shape[0] < self.sample_length :\n",
        "                \n",
        "                data[i,0:y.shape[0]] = y\n",
        "            elif y.shape[0] >= self.sample_length:\n",
        "                data[i] = y[0:self.sample_length]\n",
        "        current_labels = get_labels(header)\n",
        "        #print(current_labels)\n",
        "        labels = np.zeros(( num_classes))\n",
        "        for label in current_labels:\n",
        "            if label in classes:\n",
        "                j = classes.index(label)\n",
        "                labels[j] = 1\n",
        "#         data =recordings[:,0:self.sample_length]\n",
        "       #data = data*10/np.linalg.norm(data)\n",
        "#         for i in range(len(data)):\n",
        "#             data[i] = data[i]/max(abs(data[i]))\n",
        "#         orig_sr = int(header.split(' ')[2])\n",
        "#         for i in range(len(data)):\n",
        "#             #print(type(data[i]))\n",
        "#             data[i] = librosa.resample(data[i].astype(np.float), orig_sr, self.sample_rate, res_type='kaiser_best')        \n",
        "        recording_id = get_recording_id(header)\n",
        "        if data.shape[1] < self.sample_length :\n",
        "            print(data)\n",
        "        return (data,labels,self.header_files[index])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_omlkxauqeFu"
      },
      "source": [
        "sample_length = 4096\n",
        "BATCH_SIZE  = 256\n",
        "train_dataset = My_Dataset_separate(train_header_files, train_recording_files, twelve_leads,sample_length)\n",
        "test_dataset = My_Dataset_separate(test_header_files, test_recording_files, twelve_leads,sample_length)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1,\n",
        "                             shuffle=False, num_workers=0, pin_memory=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-u9fzzDqo6I",
        "outputId": "19e37b15-043d-4d8a-a85f-d196e54da00c"
      },
      "source": [
        "a,b,c = next(iter(train_loader))\n",
        "a.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 12, 4096])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CNN1d(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "        super(CNN1d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv1_1 = nn.Conv1d(in_channels=self.in_channels, out_channels=64, kernel_size=17, padding=8)\n",
        "        self.conv1_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=17, padding=8)\n",
        "\n",
        "        self.conv2_1 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=17, padding=8)\n",
        "        self.conv2_2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=17, padding=8)\n",
        "        self.conv3_2 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=17, padding=8)\n",
        "        self.conv3_3 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=8)\n",
        "\n",
        "        self.conv4_1 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=17, padding=8)\n",
        "        self.conv4_2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=17, padding=8)\n",
        "        self.conv4_3 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv5_1 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=17, padding=8)\n",
        "        self.conv5_2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=17, padding=8)\n",
        "        self.conv5_3 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=17, padding=8)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 30)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = self.avgpool(x)\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = self.avgpool(x)\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        x = self.avgpool(x)\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        x = self.avgpool(x)\n",
        "        x = F.relu(self.conv5_1(x))\n",
        "        x = F.relu(self.conv5_2(x))\n",
        "        x = F.relu(self.conv5_3(x))\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = F.sigmoid(self.fc3(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mWcYwS486wGN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = CNN1d(12)\n",
        "output = a(torch.rand(24,12,4096))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYAtenjP8nEj",
        "outputId": "63cae68d-ebb5-4cb9-cb01-d3ec60534e39"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdPEvDsjsYE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f2fabd-29b6-4f82-db1d-945fbfb63caf"
      },
      "source": [
        "output.shape\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([24, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-IjnvGoqsk-",
        "outputId": "1cb231b6-c7f0-4300-a638-2c9c02f618ec"
      },
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = CNN1d(12).cuda() \n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "Lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer , step_size = 20, gamma = .1)\n",
        "label_directory = 'test_data'\n",
        "output_directory = 'test_outputs'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "        since = time.time()\n",
        "        print('Epoch {}/{}'.format(epoch , num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "    \n",
        "        model.train() \n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, target, header_files) in tqdm.tqdm(enumerate(train_loader)):\n",
        "            \n",
        "            input_var = torch.autograd.Variable(inputs.cuda().float())\n",
        "            target_var = torch.autograd.Variable(target.cuda().float())\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute output\n",
        "            output= model(input_var)\n",
        "            # loss\n",
        "            loss = criterion(output, target_var)\n",
        "#             print(output)\n",
        "#             print(target_var)\n",
        "        \n",
        "            if (i%5) == 0: \n",
        "                print('step: {} totalloss: {loss:.3f} '.format(i, loss = loss))\n",
        "\n",
        "            loss.backward() \n",
        "            optimizer.step()  \n",
        "            \n",
        "\n",
        "            #print(loss.data.item())\n",
        "            \n",
        "            \n",
        "            \n",
        "            running_loss += loss.data.item()\n",
        "\n",
        "                \n",
        "            \n",
        "        Lr_scheduler.step()\n",
        "        epoch_loss = float(running_loss) / float(i)\n",
        "        print(' Epoch over  Loss: {:.5f}'.format(epoch_loss))\n",
        "        print('Testing_model............')\n",
        "        auroc,auc = test_model(model, classes, test_loader, label_directory, output_directory)\n",
        "        PATH = f'/content/drive/MyDrive/Thesis/model checkpoint classifiers/CNN1d-{epoch}-aur-{round(auroc,3)}-auc {round(auc,3)} .pth' \n",
        "        torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "1it [00:06,  6.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0 totalloss: 0.692 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6it [00:30,  5.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 5 totalloss: 0.675 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11it [00:49,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 10 totalloss: 0.507 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16it [01:07,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 15 totalloss: 0.245 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [01:35,  7.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 20 totalloss: 0.210 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26it [02:00,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 25 totalloss: 0.189 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "31it [02:08,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 30 totalloss: 0.185 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "36it [02:30,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 35 totalloss: 0.185 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "41it [02:45,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 40 totalloss: 0.184 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "46it [03:10,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 45 totalloss: 0.184 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "51it [03:28,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 50 totalloss: 0.157 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [03:32,  4.09s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuZ9bQ_Fvy6e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}